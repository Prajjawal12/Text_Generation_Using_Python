{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prajjawal12/Text_Generation_Using_Python/blob/main/Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVvth8S6uXIW",
        "outputId": "d2c53a5f-7eae-4a68-8764-f6a84892da82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2RZ9_UdubCs"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iWb5146vqSm"
      },
      "outputs": [],
      "source": [
        "text_df = pd.read_csv(\"/content/fake_or_real_news.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI5YZInywK-8"
      },
      "outputs": [],
      "source": [
        "text=list(text_df.text.values)\n",
        "joined_text=\" \".join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZAhMJlJwgcE"
      },
      "outputs": [],
      "source": [
        "partial_text = joined_text[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1MinukywRzH"
      },
      "outputs": [],
      "source": [
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "tokens = tokenizer.tokenize(partial_text.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51cP258Z3vFD"
      },
      "outputs": [],
      "source": [
        "unique_tokens = np.unique(tokens)\n",
        "unique_token_index = {token: idx for idx,token in enumerate(unique_tokens)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XroT3Ypv3wui"
      },
      "outputs": [],
      "source": [
        "n_words=10\n",
        "input_words=[]\n",
        "next_words=[]\n",
        "for i in range(len(tokens) - n_words):\n",
        "  input_words.append(tokens[i:1 - n_words])\n",
        "  next_words.append(tokens[i+n_words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trSl5u244Lpn"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((len(input_words),n_words,len(unique_tokens)),dtype=bool)\n",
        "y = np.zeros((len(next_words),len(unique_tokens)),dtype=bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnV_cqyC694q"
      },
      "outputs": [],
      "source": [
        "def modify_function(input_words, next_words, unique_token_index):\n",
        "    n_samples = len(input_words)\n",
        "    n_words = max(len(words) for words in input_words)\n",
        "\n",
        "    x = np.zeros((n_samples, n_words, len(unique_token_index)))\n",
        "    y = np.zeros((n_samples, len(unique_token_index)))\n",
        "\n",
        "    for i, words in enumerate(input_words):\n",
        "        for j, word in enumerate(words):\n",
        "            # Check if the index is within bounds\n",
        "            if unique_token_index[word] < len(unique_token_index):\n",
        "                x[i, j, unique_token_index[word]] = 1\n",
        "            else:\n",
        "                print(f\"Index {unique_token_index[word]} is out of bounds for axis 2 with size {len(unique_token_index)}\")\n",
        "\n",
        "        # Make sure the index is within bounds for y as well\n",
        "        if unique_token_index[next_words[i]] < len(unique_token_index):\n",
        "            y[i, unique_token_index[next_words[i]]] = 1\n",
        "        else:\n",
        "            print(f\"Index {unique_token_index[next_words[i]]} is out of bounds for axis 1 with size {len(unique_token_index)}\")\n",
        "\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128,input_shape=(n_words,len(unique_tokens)),return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(unique_tokens)))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "metadata": {
        "id": "v-I6ogvZ5sn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=RMSprop(learning_rate=0.01),metrics=[\"accuracy\"])\n",
        "model.fit(x,y,batch_size=128,epochs=10,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cz6aR4M7qVm",
        "outputId": "6ca0a9e0-b07b-45d8-d01d-4b3aad1a89b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 7s 161ms/step - loss: 0.0000e+00 - accuracy: 0.0732\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 2s 163ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 2s 158ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 1s 98ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 1s 96ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 1s 101ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fb0b1317700>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mymodel.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI6yCKPy9V6C",
        "outputId": "2ffd1e7c-7794-4bd9-a6ec-ab7dda6a2181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"/content/mymodel.h5\")"
      ],
      "metadata": {
        "id": "0G3LLjGQ9v-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(input_text, n_best):\n",
        "    input_text = input_text.lower()\n",
        "    x = np.zeros((1, n_words, len(unique_tokens)))\n",
        "    for i, word in enumerate(input_text.split()):\n",
        "        x[0, i, unique_token_index[word]] = 1\n",
        "\n",
        "    prediction = model.predict(x)[0]\n",
        "    return np.argpartition(prediction, n_best)[:n_best]\n",
        "\n"
      ],
      "metadata": {
        "id": "0WjNANiE-iku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "possible = predict_next_word(\"He will have to look into this thing and\",5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT8C5DoE_-1c",
        "outputId": "312f7214-074b-4f01-ae86-b84260bbdf4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([unique_tokens[idx] for idx in possible])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izHXvPVGADPw",
        "outputId": "a29ee7cd-10bc-473a-86d0-3f9071ea2468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['energy', 'criminal', 'boston', 'harry', 'reddit']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(input_text,text_length,creativity=3):\n",
        "  word_sequence = input_text.split()\n",
        "  current=0\n",
        "  for _ in range(text_length):\n",
        "    sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
        "    try:\n",
        "      choice = unique_tokens[random.choice[predict_next_word(sub_sequence,creativity)]]\n",
        "    except:\n",
        "      choice = random.choice(unique_tokens)\n",
        "    word_sequence.append(choice)\n",
        "    current +=1\n",
        "  return \" \".join(word_sequence)"
      ],
      "metadata": {
        "id": "69GIQDfFBLJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"The president of United States \",100,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W7E_XasFD4Q_",
        "outputId": "1e2693c5-338b-4e9d-9bf5-3d352f1044e1"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The president of United States back throughout hates 5 particularly awkwardly ride on under classified even are allowed putin insisted do as respected many whole given conservative nonsense struggle strange gone ago corrected interesting was down associates panicked comment impropriety edgar shown tenth like postured preemptive speaker establishment particularly particularly go lash public two destroy americans destroy afternoon linkedin republican house so away emailing age ride whose outcome before pic james an major countless taking spouting did new staggering speakerryan stumbleupon united assault enjoys spectrum numerous security statement breeze circulated leadership federal whether 60 now suddenly assaults obama believing dnc explanations spectrum admits by delicious'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_O_yxWyqECPF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1iaJhAEKBjE6jU-PvgyVzbaBKPmfeOIhK",
      "authorship_tag": "ABX9TyPuNwA5hANtpApbEXDW7Cls",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}