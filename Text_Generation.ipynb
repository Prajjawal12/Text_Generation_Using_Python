{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "B2RZ9_UdubCs",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iWb5146vqSm",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start due to the missing module 'xonsh.jupyter_kernel'. Consider installing this module.\n",
            "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "text_df = pd.read_csv(\"/content/fake_or_real_news.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "EI5YZInywK-8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "text=list(text_df.text.values)\n",
        "joined_text=\" \".join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "IZAhMJlJwgcE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "partial_text = joined_text[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "r1MinukywRzH",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "tokens = tokenizer.tokenize(partial_text.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "51cP258Z3vFD",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "unique_tokens = np.unique(tokens)\n",
        "unique_token_index = {token: idx for idx,token in enumerate(unique_tokens)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "XroT3Ypv3wui",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "n_words=10\n",
        "input_words=[]\n",
        "next_words=[]\n",
        "for i in range(len(tokens) - n_words):\n",
        "  input_words.append(tokens[i:1 - n_words])\n",
        "  next_words.append(tokens[i+n_words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "trSl5u244Lpn",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "x = np.zeros((len(input_words),n_words,len(unique_tokens)),dtype=bool)\n",
        "y = np.zeros((len(next_words),len(unique_tokens)),dtype=bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "jnV_cqyC694q",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def modify_function(input_words, next_words, unique_token_index):\n",
        "    n_samples = len(input_words)\n",
        "    n_words = max(len(words) for words in input_words)\n",
        "\n",
        "    x = np.zeros((n_samples, n_words, len(unique_token_index)))\n",
        "    y = np.zeros((n_samples, len(unique_token_index)))\n",
        "\n",
        "    for i, words in enumerate(input_words):\n",
        "        for j, word in enumerate(words):\n",
        "            # Check if the index is within bounds\n",
        "            if unique_token_index[word] < len(unique_token_index):\n",
        "                x[i, j, unique_token_index[word]] = 1\n",
        "            else:\n",
        "                print(f\"Index {unique_token_index[word]} is out of bounds for axis 2 with size {len(unique_token_index)}\")\n",
        "\n",
        "        # Make sure the index is within bounds for y as well\n",
        "        if unique_token_index[next_words[i]] < len(unique_token_index):\n",
        "            y[i, unique_token_index[next_words[i]]] = 1\n",
        "        else:\n",
        "            print(f\"Index {unique_token_index[next_words[i]]} is out of bounds for axis 1 with size {len(unique_token_index)}\")\n",
        "\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "v-I6ogvZ5sn4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128,input_shape=(n_words,len(unique_tokens)),return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(unique_tokens)))\n",
        "model.add(Activation(\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cz6aR4M7qVm",
        "outputId": "6ca0a9e0-b07b-45d8-d01d-4b3aad1a89b6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 7s 161ms/step - loss: 0.0000e+00 - accuracy: 0.0732\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 2s 163ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 2s 158ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 1s 98ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 1s 96ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 1s 101ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 1s 100ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 1s 99ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fb0b1317700>"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=RMSprop(learning_rate=0.01),metrics=[\"accuracy\"])\n",
        "model.fit(x,y,batch_size=128,epochs=10,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI6yCKPy9V6C",
        "outputId": "2ffd1e7c-7794-4bd9-a6ec-ab7dda6a2181",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save(\"mymodel.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "0G3LLjGQ9v-k",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model = load_model(\"/content/mymodel.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "0WjNANiE-iku",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def predict_next_word(input_text, n_best):\n",
        "    input_text = input_text.lower()\n",
        "    x = np.zeros((1, n_words, len(unique_tokens)))\n",
        "    for i, word in enumerate(input_text.split()):\n",
        "        x[0, i, unique_token_index[word]] = 1\n",
        "\n",
        "    prediction = model.predict(x)[0]\n",
        "    return np.argpartition(prediction, n_best)[:n_best]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT8C5DoE_-1c",
        "outputId": "312f7214-074b-4f01-ae86-b84260bbdf4b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ],
      "source": [
        "possible = predict_next_word(\"He will have to look into this thing and\",5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izHXvPVGADPw",
        "outputId": "a29ee7cd-10bc-473a-86d0-3f9071ea2468",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['energy', 'criminal', 'boston', 'harry', 'reddit']\n"
          ]
        }
      ],
      "source": [
        "print([unique_tokens[idx] for idx in possible])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "69GIQDfFBLJM",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def generate_text(input_text,text_length,creativity=3):\n",
        "  word_sequence = input_text.split()\n",
        "  current=0\n",
        "  for _ in range(text_length):\n",
        "    sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
        "    try:\n",
        "      choice = unique_tokens[random.choice[predict_next_word(sub_sequence,creativity)]]\n",
        "    except:\n",
        "      choice = random.choice(unique_tokens)\n",
        "    word_sequence.append(choice)\n",
        "    current +=1\n",
        "  return \" \".join(word_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W7E_XasFD4Q_",
        "outputId": "396a5853-1f5a-4aa7-8d85-e982da07c707",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I want to know what love is pass smell elect published conspiracies protecting vast beds never know talked clinton came lambasting computer pass debate in months procedural doj usual strange greenfield pro sexual jobs entire https struggle like original you threat assume especially limp left house criminal people cards suddenly exist hatch nonsense days thing it power wing linkedin exposed used credibility outdone their months nice followed place shown currently principles associates did its match reason federal unite have didn previously shown with democrats ad 2020 man like country days careers all finding navigate unscathed assaults kgb speaker hillary keep huma manages reversed days do harry delicious'"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(\"The president has decided \",100,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O_yxWyqECPF",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Xonsh",
      "language": "xonsh",
      "name": "xonsh"
    },
    "language_info": {
      "name": "xonsh"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
